{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ngsderive Forensic analysis tool useful in backwards computing information from next-generation sequencing data. Explore the docs \u00bb Request Feature \u00b7 Report Bug \u00b7 \u2b50 Consider starring the repo! \u2b50 Notice: ngsderive is a forensic analysis tool useful in backwards computing information from next-generation sequencing data. Notably, results are provided as a 'best guess' \u2014 the tool does not claim 100% accuracy and results should be considered with that understanding. \ud83c\udfa8 Features The following attributes can be guessed using ngsderive: Illumina Instrument. Infer which Illumina instrument was used to generate the data by matching against known instrument and flowcell naming patterns. Each guess comes with a confidence score. RNA-Seq Strandedness. Infer from the data whether RNA-Seq data was generated using a Stranded-Forward, Stranded-Reverse, or Unstranded protocol. Pre-trimmed Read Length. Compute the distribution of read lengths in the file and attempt to guess what the original read length of the experiment was. \ud83d\udcda Getting Started Installation You can install ngsderive using the Python Package Index ( PyPI ). pip install ngsderive \ud83d\udda5\ufe0f Development If you are interested in contributing to the code, please first review our CONTRIBUTING.md document. To bootstrap a development environment, please use the following commands. # Clone the repository git clone git@github.com:stjudecloud/ngsderive.git cd ngsderive # Install the project using poetry poetry install \ud83d\udea7\ufe0f Tests ngsderive provides a (currently patchy) set of tests \u2014 both unit and end-to-end. py.test \ud83e\udd1d Contributing Contributions, issues and feature requests are welcome! Feel free to check issues page . You can also take a look at the contributing guide . \ud83d\udcdd License This project is licensed as follows: All code related to the instrument subcommand is licensed under the AGPL v2.0 . This is not due any strict requirement, but out of deference to some code I drew inspiration from (and copied patterns from), the decision was made to license this code consistently. The rest of the project is licensed under the MIT License - see the LICENSE.md file for details. Copyright \u00a9 2020 St. Jude Cloud Team .","title":"Home"},{"location":"#features","text":"The following attributes can be guessed using ngsderive: Illumina Instrument. Infer which Illumina instrument was used to generate the data by matching against known instrument and flowcell naming patterns. Each guess comes with a confidence score. RNA-Seq Strandedness. Infer from the data whether RNA-Seq data was generated using a Stranded-Forward, Stranded-Reverse, or Unstranded protocol. Pre-trimmed Read Length. Compute the distribution of read lengths in the file and attempt to guess what the original read length of the experiment was.","title":"\ud83c\udfa8 Features"},{"location":"#getting-started","text":"","title":"\ud83d\udcda Getting Started"},{"location":"#installation","text":"You can install ngsderive using the Python Package Index ( PyPI ). pip install ngsderive","title":"Installation"},{"location":"#development","text":"If you are interested in contributing to the code, please first review our CONTRIBUTING.md document. To bootstrap a development environment, please use the following commands. # Clone the repository git clone git@github.com:stjudecloud/ngsderive.git cd ngsderive # Install the project using poetry poetry install","title":"\ud83d\udda5\ufe0f Development"},{"location":"#tests","text":"ngsderive provides a (currently patchy) set of tests \u2014 both unit and end-to-end. py.test","title":"\ud83d\udea7\ufe0f Tests"},{"location":"#contributing","text":"Contributions, issues and feature requests are welcome! Feel free to check issues page . You can also take a look at the contributing guide .","title":"\ud83e\udd1d Contributing"},{"location":"#license","text":"This project is licensed as follows: All code related to the instrument subcommand is licensed under the AGPL v2.0 . This is not due any strict requirement, but out of deference to some code I drew inspiration from (and copied patterns from), the decision was made to license this code consistently. The rest of the project is licensed under the MIT License - see the LICENSE.md file for details. Copyright \u00a9 2020 St. Jude Cloud Team .","title":"\ud83d\udcdd License"},{"location":"subcommands/encoding/","text":"encoding The encoding subcommand detects the likely PHRED score encoding scheme used for FASTQ and BAM files. PHRED scores are encoded as ASCII characters, but which ASCII characters encode for which relative quality scores depends on the build and generation of the sequencing machine used. The encoding subcommand supports PHRED+33 (AKA Illumina1.8+ or Sanger), Illumina1.0, and Illumina1.3 quality encoding formats. The BAM specification calls for PHRED+33 , however this is also the most permissive encoding. It is possible for a stricter encoding to be mis-translated as PHRED+33 and appear to be of higher quality than it is in truth. This is due to Illumina1.3 using ASCII characters that are a subset of those in Illumina 1.0 and Illumina 1.0 using a subset of characters in Sanger format (that is Illumina1.3 \u2282 Illumina1.0 and Illumina1.0 \u2282 Sanger). This subcommand can be used to check if base scores are suspiciously high throughout a BAM, and a mis-translation may have occurred. As a hypothetical example of a mis-translation; a FASTQ sequenced by an Illumina1.3 machine has PHRED quality scores ranging from 6-22. They would be encoded as ASCII values 70-86. If those ASCII values are not adjusted during BAM alignment, someone decoding the PHRED score according to the PHRED+33 specification would think the quality range for that sample was 37-53. This is erroneously high, and may convey undue confidence in the quality of the BAM. ngsderive 's encoding check implementation is based on details of the encoding schemes described [here][https://en.wikipedia.org/wiki/FASTQ_format#Encoding]. Limitations All 3 possible encodings have the same upper range, and only differ in terms of lower quality scores. Thus if the provided read data is all of high quality, it may be classified as a stricter encoding than was originally used to generate the data. If the downstream use of this value is needed to ensure all PHRED scores are within the derived encoding, use --n-samples -1 to parse the entire file.","title":"encoding"},{"location":"subcommands/encoding/#encoding","text":"The encoding subcommand detects the likely PHRED score encoding scheme used for FASTQ and BAM files. PHRED scores are encoded as ASCII characters, but which ASCII characters encode for which relative quality scores depends on the build and generation of the sequencing machine used. The encoding subcommand supports PHRED+33 (AKA Illumina1.8+ or Sanger), Illumina1.0, and Illumina1.3 quality encoding formats. The BAM specification calls for PHRED+33 , however this is also the most permissive encoding. It is possible for a stricter encoding to be mis-translated as PHRED+33 and appear to be of higher quality than it is in truth. This is due to Illumina1.3 using ASCII characters that are a subset of those in Illumina 1.0 and Illumina 1.0 using a subset of characters in Sanger format (that is Illumina1.3 \u2282 Illumina1.0 and Illumina1.0 \u2282 Sanger). This subcommand can be used to check if base scores are suspiciously high throughout a BAM, and a mis-translation may have occurred. As a hypothetical example of a mis-translation; a FASTQ sequenced by an Illumina1.3 machine has PHRED quality scores ranging from 6-22. They would be encoded as ASCII values 70-86. If those ASCII values are not adjusted during BAM alignment, someone decoding the PHRED score according to the PHRED+33 specification would think the quality range for that sample was 37-53. This is erroneously high, and may convey undue confidence in the quality of the BAM. ngsderive 's encoding check implementation is based on details of the encoding schemes described [here][https://en.wikipedia.org/wiki/FASTQ_format#Encoding].","title":"encoding"},{"location":"subcommands/encoding/#limitations","text":"All 3 possible encodings have the same upper range, and only differ in terms of lower quality scores. Thus if the provided read data is all of high quality, it may be classified as a stricter encoding than was originally used to generate the data. If the downstream use of this value is needed to ensure all PHRED scores are within the derived encoding, use --n-samples -1 to parse the entire file.","title":"Limitations"},{"location":"subcommands/instrument/","text":"instrument The instrument subcommand will attempt to backward compute the machine that generated a NGS file using (1) the instrument id(s) and (2) the flowcell id(s). Limitations This command may not comprehensively detect the correct machines as there is no published catalog of Illumina serial numbers. As we encounter more serial numbers in practice, we update this code.","title":"instrument"},{"location":"subcommands/instrument/#instrument","text":"The instrument subcommand will attempt to backward compute the machine that generated a NGS file using (1) the instrument id(s) and (2) the flowcell id(s).","title":"instrument"},{"location":"subcommands/instrument/#limitations","text":"This command may not comprehensively detect the correct machines as there is no published catalog of Illumina serial numbers. As we encounter more serial numbers in practice, we update this code.","title":"Limitations"},{"location":"subcommands/readlen/","text":"readlen The readlen subcommand can be used to compute the read length used during sequencing can be estimated (or reported as inconclusive). Algorithm At the time of writing, the algorithm used is roughly: Compute distribution of read lengths for the first --n-samples reads in a file. Assuming read length in the file can only decrease from the actual read length (from adapter trimming or similar), the putative maximum read length is considered to be the highest detected read length. If the percentage of reads that are evidence for the putative maximum read length makes up at least --majority-vote-cutoff % of the reads, the putative read length is considered to be confirmed. If not, the consensus read length will be return as -1 (could not determine). For example, if 100bp is the maximum read length detected and 85% percent of the reads support that claim, then we considered 100bp as the consensus read length. If only 30% of the reads indicated 100bp, the tool cannot report a consensus).","title":"readlen"},{"location":"subcommands/readlen/#readlen","text":"The readlen subcommand can be used to compute the read length used during sequencing can be estimated (or reported as inconclusive).","title":"readlen"},{"location":"subcommands/readlen/#algorithm","text":"At the time of writing, the algorithm used is roughly: Compute distribution of read lengths for the first --n-samples reads in a file. Assuming read length in the file can only decrease from the actual read length (from adapter trimming or similar), the putative maximum read length is considered to be the highest detected read length. If the percentage of reads that are evidence for the putative maximum read length makes up at least --majority-vote-cutoff % of the reads, the putative read length is considered to be confirmed. If not, the consensus read length will be return as -1 (could not determine). For example, if 100bp is the maximum read length detected and 85% percent of the reads support that claim, then we considered 100bp as the consensus read length. If only 30% of the reads indicated 100bp, the tool cannot report a consensus).","title":"Algorithm"},{"location":"subcommands/strandedness/","text":"strandedness The strandedness subcommand can be used to determine strandedness of RNA-Seq samples. Note that due to the need to (1) to examine the alignment status of a read [not included in FASTQ] and (2) fetch regions using random access [not available with SAM files], only BAM files are currently supported for this subcommand. Strandedness can estimated by observing the following characteristics of a particular read: Whether the read is read 1 or read 2 (\"read ordinal\"). Whether the read was aligned to the + or - strand (\"read strand\") Given a gene model, whether a feature of interest (usually a gene) falls on the + or - strand (\"gene strand\"). A shorthand notation for the state of a read can be achieved by simply concatenating the three characteristics above (e.g., 1+- means that a read 1 was aligned to the positive strand and a gene was observed at the same location on the negative strand). Given the notation above, the following lookup table can be used to see whether a read is evidence for forward-strandedness or reverse-strandedness: Patterns Evidence for strandedness type 1++ , 1-- , 2+- , 2-+ Forward 2++ , 2-- , 1+- , 1-+ Reverse By default, the strandedness check is designed to work with the GENCODE geneset. Either a GTF or GFF file can be used as the gene model \u2014 you can use the following one liner to prepare the latest geneset for hg38. # hg38 curl ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_32/gencode.v32.annotation.gff3.gz | gunzip -c | sort -k1,1 -k4,4n -k5,5n | bgzip > gencode.v32.annotation.gff3.gz tabix -p gff gencode.v32.annotation.gff3.gz If you would like to use the script on hg19, it takes a little more finesse (given the different formats of the attribute column between versions): # hg19 curl ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_32/GRCh37_mapping/gencode.v32lift37.annotation.gtf.gz | gunzip -c | sort -k1,1 -k4,4n -k5,5n | python <(cat <<END import re import sys for line in [l.strip() for l in sys.stdin]: if line.startswith(\"#\"): print(line) else: columns = line.split('\\t') if len(columns) != 9: raise RuntimeError(\"Unexpected column number: {}\".format(len(columns))) print('\\t'.join(columns[0:8]), end=\"\\t\") attrs_post = [] for attr in columns[8].split(\";\"): groups = re.match(r\"\\s?(\\S+) (\\S+)\\s?\", attr) if groups: key = groups.group(1) value = groups.group(2).replace(\"\\\"\", \"\").replace(\" \", \",\") attrs_post.append(key + \"=\" + value) print(\";\".join(attrs_post)) END ) | sed 's/^chrM/chrMT/g' | sed 's/^chr//g' | bgzip > gencode.v32lift37.annotation.gtf.gz tabix -p gff gencode.v32lift37.annotation.gtf.gz Algorithm At the time of writing, the algorithm works roughly like this: The gene model is read in and only gene features are retained. For --n-genes times, a randomly sampled gene is selected from the gene model. The gene must pass a quality check. Of particular interest, The gene must not be an overlapping feature on the opposite strand which would present ambiguous results. Optionally , the gene must be a protein coding gene. Optionally , the gene must have at least --minimum-reads-per-gene minimum reads per gene. All of the reads from that region of the genome are extracted and put through several quality filters including but not limited to: The read must not be marked as QC-failed. The read must not be marked as a duplicate. The read must not be marked as secondary. The read must not be unmapped. Optionally , the read have a minimum MAPQ score. For all reads that pass the above filters, compute the evidence and tally results. This lookup table is used for the classification of strandedness based on the evidence: Lookup Value 40% <= forward_reads_pct <= 60% Unstranded 80% <= forward_reads_pct Stranded-Forward 80% <= reverse_reads_pct Stranded-Reverse Else Inconclusive The tool will repeat the strandedness test at most --max-tries times to try to find a non- Inconclusive prediction. Differences The most popular strandedness inference tool that the author is aware of is RSeQC's infer_experiment.py . The main difference is that RSeQC starts at the beginning of the BAM file and takes the first n reads that match its criteria. If the BAM is coordinate sorted, this would mean its not uncommon to have all of the evidence at the beginning of chr1 . Anecdotally, this method differs in that it is slightly slower than infer_experiment.py but is expected to be more robust to biases caused by which reads are sampled. Limitations Does not yet work with single-end data (simply because the author doesn't have any on hand). The tool will throw an error if any unpaired reads are discovered (let us know in the issues if you need this supported). Though hundreds of Unstranded and Stranded-Reverse data has been tested and verified, Stranded-Forward data has not been tested to work with this tool (simply because the author doesn't have on hand). We do not anticipate any issues since Stranded-Reverse is working well.","title":"strandedness"},{"location":"subcommands/strandedness/#strandedness","text":"The strandedness subcommand can be used to determine strandedness of RNA-Seq samples. Note that due to the need to (1) to examine the alignment status of a read [not included in FASTQ] and (2) fetch regions using random access [not available with SAM files], only BAM files are currently supported for this subcommand. Strandedness can estimated by observing the following characteristics of a particular read: Whether the read is read 1 or read 2 (\"read ordinal\"). Whether the read was aligned to the + or - strand (\"read strand\") Given a gene model, whether a feature of interest (usually a gene) falls on the + or - strand (\"gene strand\"). A shorthand notation for the state of a read can be achieved by simply concatenating the three characteristics above (e.g., 1+- means that a read 1 was aligned to the positive strand and a gene was observed at the same location on the negative strand). Given the notation above, the following lookup table can be used to see whether a read is evidence for forward-strandedness or reverse-strandedness: Patterns Evidence for strandedness type 1++ , 1-- , 2+- , 2-+ Forward 2++ , 2-- , 1+- , 1-+ Reverse By default, the strandedness check is designed to work with the GENCODE geneset. Either a GTF or GFF file can be used as the gene model \u2014 you can use the following one liner to prepare the latest geneset for hg38. # hg38 curl ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_32/gencode.v32.annotation.gff3.gz | gunzip -c | sort -k1,1 -k4,4n -k5,5n | bgzip > gencode.v32.annotation.gff3.gz tabix -p gff gencode.v32.annotation.gff3.gz If you would like to use the script on hg19, it takes a little more finesse (given the different formats of the attribute column between versions): # hg19 curl ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_32/GRCh37_mapping/gencode.v32lift37.annotation.gtf.gz | gunzip -c | sort -k1,1 -k4,4n -k5,5n | python <(cat <<END import re import sys for line in [l.strip() for l in sys.stdin]: if line.startswith(\"#\"): print(line) else: columns = line.split('\\t') if len(columns) != 9: raise RuntimeError(\"Unexpected column number: {}\".format(len(columns))) print('\\t'.join(columns[0:8]), end=\"\\t\") attrs_post = [] for attr in columns[8].split(\";\"): groups = re.match(r\"\\s?(\\S+) (\\S+)\\s?\", attr) if groups: key = groups.group(1) value = groups.group(2).replace(\"\\\"\", \"\").replace(\" \", \",\") attrs_post.append(key + \"=\" + value) print(\";\".join(attrs_post)) END ) | sed 's/^chrM/chrMT/g' | sed 's/^chr//g' | bgzip > gencode.v32lift37.annotation.gtf.gz tabix -p gff gencode.v32lift37.annotation.gtf.gz","title":"strandedness"},{"location":"subcommands/strandedness/#algorithm","text":"At the time of writing, the algorithm works roughly like this: The gene model is read in and only gene features are retained. For --n-genes times, a randomly sampled gene is selected from the gene model. The gene must pass a quality check. Of particular interest, The gene must not be an overlapping feature on the opposite strand which would present ambiguous results. Optionally , the gene must be a protein coding gene. Optionally , the gene must have at least --minimum-reads-per-gene minimum reads per gene. All of the reads from that region of the genome are extracted and put through several quality filters including but not limited to: The read must not be marked as QC-failed. The read must not be marked as a duplicate. The read must not be marked as secondary. The read must not be unmapped. Optionally , the read have a minimum MAPQ score. For all reads that pass the above filters, compute the evidence and tally results. This lookup table is used for the classification of strandedness based on the evidence: Lookup Value 40% <= forward_reads_pct <= 60% Unstranded 80% <= forward_reads_pct Stranded-Forward 80% <= reverse_reads_pct Stranded-Reverse Else Inconclusive The tool will repeat the strandedness test at most --max-tries times to try to find a non- Inconclusive prediction.","title":"Algorithm"},{"location":"subcommands/strandedness/#differences","text":"The most popular strandedness inference tool that the author is aware of is RSeQC's infer_experiment.py . The main difference is that RSeQC starts at the beginning of the BAM file and takes the first n reads that match its criteria. If the BAM is coordinate sorted, this would mean its not uncommon to have all of the evidence at the beginning of chr1 . Anecdotally, this method differs in that it is slightly slower than infer_experiment.py but is expected to be more robust to biases caused by which reads are sampled.","title":"Differences"},{"location":"subcommands/strandedness/#limitations","text":"Does not yet work with single-end data (simply because the author doesn't have any on hand). The tool will throw an error if any unpaired reads are discovered (let us know in the issues if you need this supported). Though hundreds of Unstranded and Stranded-Reverse data has been tested and verified, Stranded-Forward data has not been tested to work with this tool (simply because the author doesn't have on hand). We do not anticipate any issues since Stranded-Reverse is working well.","title":"Limitations"}]}